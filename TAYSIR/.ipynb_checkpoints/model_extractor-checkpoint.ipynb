{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAYSIR competition - Track 1 Starter Kit\n",
    "\n",
    "### Welcome!\n",
    "\n",
    "This is a notebook to show the structure of a code to participate to the competition.\n",
    "\n",
    "You can also check the baseline notebook (available in the same archive) for more details about the TAYSIR models and how to use them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare your environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%pip install -q mlflow torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import mlflow\n",
    "from utils import predict, PytorchInference\n",
    "#print('PyTorch version :', torch.__version__)\n",
    "#print('MLflow version :', mlflow.__version__)\n",
    "import sys\n",
    "import pandas as pd\n",
    "#print(\"Your python version:\", sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was tested with:\n",
    "* Torch version: 1.11.0+cu102\n",
    "* MLFlow version: 1.25.1\n",
    "* Python version: 3.8.10 [GCC 9.4.0]\n",
    "\n",
    "Python versions starting at 3.7 are supposed to work (but have not been tested).\n",
    "## Choosing the phase\n",
    "\n",
    "First you must select one of the phases/datasets we provide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACK = 1 #always for his track\n",
    "DATASET = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/03/22 20:56:45 WARNING mlflow.pytorch: Stored model version '1.13.1+cpu' does not match installed PyTorch version '2.0.0+cu117'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TNetwork(\n",
       "  28, 2, neurons_per_layer=64, cell_type=lstmx.LSTMx, batch_size=64, patience=5, task=bin\n",
       "  (mach[0]): LSTMx(\n",
       "    27, 64, batch_first=True\n",
       "    (drop_layer): Dropout(p=0, inplace=False)\n",
       "    (forward_layers[0]): LSTMCell(27, 64)\n",
       "  )\n",
       "  (dense): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=2, bias=True)\n",
       "    (1): Sigmoid()\n",
       "    (2): Softmax(dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DistilBertForSequenceClassification\n",
    "\n",
    "model_name = f\"models/1.{DATASET}.taysir.model\"\n",
    "\n",
    "model = mlflow.pytorch.load_model(model_name)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The alphabet contains 27 symbols.\n",
      "The type of the recurrent cells is LSTMx\n"
     ]
    }
   ],
   "source": [
    "try:#RNN\n",
    "    nb_letters = model.input_size - 1\n",
    "    cell_type = model.cell_type\n",
    "\n",
    "    print(\"The alphabet contains\", nb_letters, \"symbols.\")\n",
    "    print(\"The type of the recurrent cells is\", cell_type.__name__)\n",
    "except:\n",
    "    nb_letters = model.distilbert.config.vocab_size - 2\n",
    "    print(\"The alphabet contains\", nb_letters, \"symbols.\")\n",
    "    print(\"The model is a transformer (DistilBertForSequenceClassification)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "The input data is in the following format :\n",
    "\n",
    "```\n",
    "[Number of sequences] [Alphabet size]\n",
    "[Length of sequence] [List of symbols]\n",
    "[Length of sequence] [List of symbols]\n",
    "[Length of sequence] [List of symbols]\n",
    "...\n",
    "[Length of sequence] [List of symbols]\n",
    "```\n",
    "\n",
    "For example the following data :\n",
    "\n",
    "```\n",
    "5 10\n",
    "6 8 6 5 1 6 7 4 9\n",
    "12 8 6 9 4 6 8 2 1 0 6 5 9\n",
    "7 8 9 4 3 0 4 9\n",
    "4 8 0 4 9\n",
    "8 8 1 5 2 6 0 5 3 9\n",
    "```\n",
    "\n",
    "is composed of 5 sequences and has an alphabet size of 10 (so symbols are between 0 and 9) and the first sequence is composed of 6 symbols (8 6 5 1 6 7 4 9), notice that 8 is the start symbol and 9 is the end symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pythautomata.base_types.alphabet import Alphabet\n",
    "\n",
    "file = f\"datasets/1.{DATASET}.taysir.valid.words\"\n",
    "\n",
    "alphabet = None\n",
    "sequences = []\n",
    "\n",
    "#In the competition the empty sequence is defined as [alphabet_size - 2, alphabet size -1]\n",
    "#For example with the alphabet of size 22 the empty sequence is [20, 21]\n",
    "empty_sequence_len = 2\n",
    "\n",
    "with open(file) as f:\n",
    "    a = f.readline() #Skip first line (number of sequences, alphabet size)\n",
    "    headline = a.split(' ')\n",
    "    alphabet_size = int(headline[1].strip())\n",
    "    alphabet = Alphabet.from_strings([str(x) for x in range(alphabet_size - empty_sequence_len)])\n",
    "    \n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        seq = line.split(' ')\n",
    "        seq = [int(i) for i in seq[1:]] #Remove first value (length of sequence) and cast to int\n",
    "        sequences.append(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable *sequences* is thus **a list of lists**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 first sequences:\n",
      "[25, 24, 9, 20, 14, 22, 13, 13, 13, 13, 13, 22, 20, 10, 13, 1, 13, 22, 13, 13, 11, 13, 1, 11, 10, 1, 14, 10, 13, 11, 11, 19, 11, 7, 24, 3, 12, 7, 5, 19, 5, 13, 19, 20, 7, 23, 21, 15, 10, 12, 19, 10, 14, 5, 15, 3, 23, 7, 20, 15, 22, 1, 10, 19, 19, 13, 19, 10, 22, 22, 0, 12, 13, 9, 7, 11, 10, 22, 11, 1, 7, 23, 5, 14, 0, 10, 12, 1, 15, 3, 21, 20, 13, 22, 1, 1, 10, 15, 9, 3, 12, 20, 13, 22, 1, 22, 3, 8, 12, 22, 10, 22, 13, 23, 10, 20, 3, 10, 14, 10, 12, 5, 20, 14, 8, 0, 21, 13, 10, 10, 22, 10, 19, 20, 5, 0, 9, 9, 9, 7, 11, 14, 14, 5, 23, 5, 19, 1, 22, 11, 19, 13, 11, 13, 12, 13, 26]\n",
      "[25, 24, 14, 0, 22, 15, 15, 14, 10, 3, 5, 3, 13, 5, 12, 7, 7, 20, 7, 22, 8, 23, 16, 5, 10, 21, 14, 14, 14, 21, 1, 5, 19, 12, 0, 20, 9, 14, 8, 13, 21, 22, 13, 21, 1, 21, 11, 22, 0, 10, 20, 9, 9, 3, 24, 13, 23, 3, 10, 11, 12, 7, 20, 1, 5, 21, 15, 5, 21, 14, 23, 21, 3, 14, 16, 14, 24, 12, 22, 19, 22, 13, 12, 12, 12, 3, 1, 20, 22, 0, 19, 15, 10, 10, 1, 15, 1, 10, 13, 12, 10, 19, 22, 16, 1, 21, 24, 23, 23, 7, 19, 0, 11, 13, 23, 12, 20, 11, 1, 14, 1, 12, 23, 23, 15, 22, 13, 22, 12, 8, 14, 23, 12, 13, 9, 11, 22, 23, 11, 19, 21, 20, 13, 1, 22, 22, 22, 19, 12, 21, 14, 22, 13, 23, 10, 14, 14, 5, 15, 12, 15, 22, 23, 7, 10, 15, 23, 3, 23, 1, 11, 22, 23, 22, 9, 16, 5, 16, 10, 8, 9, 0, 21, 19, 7, 20, 7, 8, 9, 22, 3, 8, 20, 20, 15, 23, 23, 7, 19, 8, 15, 5, 11, 8, 7, 3, 5, 10, 3, 21, 12, 11, 22, 23, 1, 12, 20, 1, 12, 5, 9, 13, 12, 5, 19, 8, 22, 11, 14, 14, 12, 22, 14, 23, 15, 21, 16, 22, 23, 24, 19, 13, 13, 1, 20, 21, 12, 13, 22, 24, 22, 22, 11, 14, 11, 21, 0, 21, 22, 23, 21, 21, 3, 3, 22, 13, 24, 5, 12, 0, 22, 21, 22, 3, 10, 0, 3, 5, 8, 12, 22, 14, 8, 1, 12, 22, 19, 22, 12, 14, 9, 22, 12, 24, 19, 22, 15, 19, 22, 15, 20, 1, 26]\n",
      "[25, 24, 14, 1, 1, 13, 13, 13, 5, 21, 22, 10, 20, 12, 11, 20, 23, 7, 13, 1, 11, 23, 12, 22, 21, 14, 7, 16, 1, 19, 1, 19, 23, 9, 13, 23, 5, 1, 13, 14, 3, 21, 9, 23, 20, 10, 7, 12, 8, 22, 24, 22, 1, 12, 21, 22, 14, 1, 13, 12, 1, 22, 22, 13, 1, 10, 7, 5, 1, 23, 21, 12, 20, 26]\n",
      "[25, 24, 20, 19, 1, 19, 8, 7, 1, 5, 20, 9, 1, 19, 22, 0, 9, 21, 22, 23, 23, 8, 1, 5, 22, 22, 14, 20, 22, 23, 5, 22, 22, 0, 14, 1, 22, 3, 11, 1, 1, 13, 20, 5, 23, 10, 22, 22, 1, 1, 13, 0, 13, 13, 22, 10, 14, 3, 12, 24, 10, 13, 24, 23, 21, 5, 15, 20, 11, 20, 1, 20, 14, 21, 3, 1, 13, 22, 10, 1, 13, 5, 20, 5, 13, 22, 14, 0, 22, 14, 13, 21, 0, 15, 24, 0, 20, 11, 12, 8, 5, 19, 22, 22, 11, 16, 20, 20, 22, 20, 20, 16, 14, 5, 21, 22, 23, 20, 15, 1, 21, 8, 3, 15, 22, 10, 11, 5, 10, 1, 14, 10, 22, 13, 22, 20, 0, 24, 22, 3, 23, 1, 23, 11, 5, 21, 22, 20, 22, 8, 5, 22, 3, 10, 20, 23, 8, 14, 19, 14, 11, 20, 23, 10, 5, 16, 16, 13, 5, 20, 22, 5, 13, 14, 14, 15, 1, 1, 19, 5, 20, 10, 3, 20, 20, 10, 15, 13, 20, 10, 15, 15, 21, 5, 13, 11, 23, 5, 1, 11, 7, 15, 14, 23, 23, 10, 20, 5, 13, 10, 0, 0, 10, 1, 5, 22, 23, 1, 22, 22, 20, 3, 1, 8, 22, 11, 15, 13, 20, 13, 19, 9, 5, 13, 23, 11, 16, 5, 22, 5, 13, 22, 10, 14, 23, 22, 10, 23, 1, 10, 20, 20, 10, 19, 5, 5, 12, 1, 14, 20, 15, 21, 19, 13, 9, 5, 15, 7, 1, 1, 19, 22, 12, 1, 5, 10, 10, 24, 22, 19, 23, 22, 19, 1, 22, 22, 22, 1, 14, 11, 5, 23, 3, 13, 5, 22, 22, 5, 14, 9, 7, 21, 14, 20, 22, 10, 26]\n",
      "[25, 24, 13, 12, 23, 11, 8, 8, 7, 5, 11, 13, 23, 19, 24, 22, 7, 13, 14, 1, 21, 22, 9, 22, 12, 13, 9, 12, 22, 21, 7, 7, 15, 11, 7, 16, 10, 1, 3, 20, 21, 1, 9, 24, 5, 9, 12, 19, 19, 3, 7, 20, 5, 14, 1, 20, 12, 7, 13, 15, 1, 15, 12, 12, 21, 19, 9, 23, 22, 13, 13, 7, 7, 13, 7, 10, 9, 13, 13, 15, 14, 24, 13, 7, 22, 5, 14, 9, 23, 13, 15, 19, 9, 7, 23, 21, 3, 23, 22, 14, 22, 20, 19, 19, 24, 22, 9, 12, 19, 15, 1, 21, 23, 12, 22, 20, 8, 1, 13, 13, 13, 21, 9, 15, 21, 14, 23, 16, 1, 9, 3, 22, 10, 5, 22, 9, 21, 9, 19, 7, 20, 5, 23, 7, 9, 24, 1, 1, 5, 5, 13, 15, 22, 13, 0, 20, 10, 14, 14, 21, 24, 12, 10, 9, 19, 22, 9, 3, 3, 20, 1, 20, 22, 15, 12, 9, 22, 15, 7, 1, 14, 14, 7, 19, 3, 24, 7, 14, 14, 13, 21, 0, 22, 9, 24, 24, 22, 21, 8, 19, 12, 3, 21, 8, 12, 20, 23, 19, 1, 19, 10, 23, 9, 14, 22, 23, 14, 13, 22, 7, 10, 15, 14, 7, 20, 9, 22, 9, 3, 9, 22, 5, 20, 13, 23, 16, 0, 22, 14, 20, 7, 13, 19, 5, 13, 21, 15, 13, 11, 1, 22, 10, 22, 5, 9, 13, 22, 10, 19, 5, 22, 1, 12, 1, 14, 15, 12, 15, 23, 5, 21, 5, 5, 22, 13, 1, 20, 23, 7, 5, 22, 1, 15, 23, 19, 12, 21, 12, 23, 15, 21, 12, 13, 13, 22, 9, 24, 23, 9, 0, 15, 14, 22, 15, 14, 22, 12, 22, 24, 19, 13, 15, 15, 3, 19, 19, 11, 19, 22, 12, 19, 19, 23, 15, 20, 22, 14, 12, 12, 22, 14, 22, 1, 23, 8, 19, 22, 1, 1, 3, 19, 12, 3, 3, 1, 12, 23, 21, 1, 10, 21, 22, 9, 16, 1, 11, 23, 8, 15, 1, 12, 15, 20, 16, 21, 12, 7, 13, 1, 15, 20, 7, 19, 15, 9, 20, 12, 23, 23, 15, 5, 22, 5, 15, 22, 22, 12, 1, 1, 8, 19, 11, 22, 5, 22, 0, 23, 13, 1, 8, 19, 5, 10, 12, 3, 23, 21, 8, 3, 11, 21, 10, 15, 14, 23, 23, 12, 9, 3, 9, 10, 15, 13, 13, 23, 24, 21, 22, 22, 14, 13, 12, 19, 11, 7, 23, 21, 3, 8, 13, 22, 22, 13, 23, 9, 15, 22, 24, 23, 8, 7, 16, 12, 3, 22, 10, 15, 9, 22, 19, 1, 19, 23, 9, 14, 19, 14, 23, 13, 23, 15, 26]\n",
      "[25, 24, 19, 13, 9, 20, 14, 22, 12, 22, 14, 9, 22, 22, 20, 9, 1, 5, 13, 11, 19, 14, 14, 9, 5, 14, 12, 13, 14, 21, 13, 22, 12, 14, 15, 3, 22, 15, 12, 11, 10, 1, 22, 22, 1, 22, 20, 8, 5, 24, 10, 14, 0, 12, 7, 11, 9, 23, 21, 9, 22, 13, 13, 5, 12, 13, 21, 15, 22, 0, 8, 15, 3, 16, 1, 1, 23, 19, 13, 19, 23, 9, 7, 9, 5, 21, 1, 7, 22, 22, 19, 5, 14, 22, 15, 12, 11, 12, 1, 5, 23, 21, 8, 13, 20, 10, 21, 23, 5, 13, 13, 22, 13, 15, 22, 19, 22, 11, 12, 10, 15, 16, 7, 12, 22, 1, 13, 20, 22, 23, 9, 13, 14, 24, 19, 9, 7, 19, 1, 5, 21, 12, 24, 13, 23, 3, 23, 22, 3, 1, 5, 13, 12, 14, 23, 19, 22, 19, 7, 15, 22, 22, 22, 19, 20, 23, 7, 22, 20, 1, 9, 14, 5, 14, 19, 1, 1, 21, 14, 23, 21, 23, 14, 1, 23, 9, 10, 22, 10, 13, 5, 13, 12, 23, 22, 12, 1, 19, 19, 15, 15, 22, 22, 8, 13, 3, 21, 13, 14, 22, 11, 10, 24, 22, 22, 23, 22, 9, 19, 23, 23, 9, 23, 10, 19, 23, 19, 13, 1, 15, 9, 23, 20, 19, 23, 20, 7, 14, 20, 22, 5, 13, 1, 10, 13, 5, 5, 1, 15, 13, 22, 10, 7, 5, 5, 12, 5, 5, 14, 10, 5, 13, 7, 1, 15, 9, 23, 19, 19, 12, 5, 21, 0, 24, 13, 22, 1, 20, 5, 5, 1, 0, 5, 21, 20, 15, 1, 21, 15, 22, 9, 13, 22, 15, 22, 10, 15, 11, 22, 23, 22, 14, 22, 24, 12, 23, 13, 14, 12, 12, 14, 14, 19, 19, 5, 19, 12, 19, 0, 11, 13, 21, 22, 13, 22, 21, 1, 5, 19, 22, 22, 1, 14, 8, 22, 1, 11, 1, 9, 23, 20, 3, 11, 24, 20, 12, 13, 13, 0, 13, 20, 1, 9, 1, 11, 9, 13, 1, 3, 21, 15, 13, 13, 22, 22, 1, 5, 10, 23, 13, 23, 12, 10, 1, 1, 12, 1, 23, 13, 10, 7, 22, 11, 7, 5, 20, 11, 5, 5, 5, 7, 10, 22, 0, 19, 7, 19, 24, 19, 23, 21, 9, 13, 13, 22, 22, 13, 22, 1, 9, 5, 13, 23, 12, 5, 11, 14, 12, 23, 1, 15, 8, 8, 13, 9, 22, 22, 11, 22, 23, 20, 12, 22, 24, 1, 14, 9, 10, 23, 15, 23, 10, 15, 1, 13, 0, 7, 0, 5, 19, 13, 22, 22, 12, 10, 22, 19, 15, 1, 12, 5, 1, 10, 3, 22, 11, 24, 22, 24, 12, 21, 22, 23, 10, 22, 22, 12, 20, 1, 19, 14, 11, 19, 5, 15, 1, 0, 23, 13, 13, 13, 5, 10, 1, 13, 13, 20, 13, 13, 9, 19, 19, 20, 5, 11, 3, 20, 12, 21, 14, 24, 13, 1, 22, 1, 9, 0, 22, 8, 14, 14, 19, 19, 19, 12, 10, 3, 12, 22, 21, 10, 14, 23, 24, 19, 14, 22, 10, 13, 5, 13, 7, 13, 23, 10, 15, 9, 13, 20, 22, 11, 3, 14, 12, 9, 22, 5, 9, 22, 13, 3, 12, 10, 5, 9, 5, 19, 8, 1, 21, 22, 21, 12, 0, 1, 20, 0, 20, 3, 13, 23, 22, 13, 21, 23, 3, 15, 12, 12, 20, 13, 11, 20, 22, 12, 8, 5, 23, 11, 13, 22, 20, 15, 1, 5, 19, 9, 19, 12, 1, 19, 5, 22, 1, 12, 21, 5, 10, 13, 11, 14, 13, 12, 12, 5, 1, 9, 22, 22, 19, 1, 23, 12, 14, 7, 12, 12, 12, 7, 19, 12, 12, 22, 12, 15, 13, 24, 10, 23, 7, 1, 13, 5, 13, 24, 12, 15, 12, 5, 13, 13, 19, 13, 22, 10, 12, 5, 0, 24, 3, 23, 10, 13, 11, 20, 14, 11, 3, 22, 12, 11, 14, 23, 12, 15, 22, 23, 13, 0, 14, 14, 8, 20, 3, 12, 10, 23, 21, 15, 1, 13, 22, 1, 1, 22, 16, 21, 0, 13, 14, 14, 3, 3, 15, 23, 0, 7, 23, 11, 9, 16, 9, 11, 10, 22, 11, 22, 15, 23, 11, 23, 11, 19, 14, 23, 15, 7, 5, 20, 12, 13, 23, 21, 15, 0, 14, 20, 19, 14, 22, 12, 12, 12, 3, 12, 15, 14, 23, 13, 14, 19, 5, 22, 21, 7, 20, 13, 12, 1, 5, 15, 14, 0, 10, 11, 23, 23, 22, 10, 19, 19, 3, 12, 15, 22, 0, 12, 23, 23, 24, 12, 23, 22, 9, 15, 9, 8, 5, 23, 9, 13, 10, 19, 23, 20, 19, 19, 19, 20, 12, 12, 12, 19, 5, 23, 1, 7, 12, 12, 23, 19, 19, 14, 12, 9, 19, 13, 22, 22, 5, 19, 1, 13, 0, 19, 23, 23, 5, 13, 22, 13, 23, 13, 22, 10, 10, 1, 20, 13, 19, 1, 20, 15, 23, 20, 3, 11, 9, 5, 23, 15, 3, 3, 24, 1, 15, 7, 10, 7, 12, 21, 13, 24, 13, 23, 13, 0, 23, 10, 12, 23, 13, 10, 10, 5, 12, 1, 13, 5, 14, 11, 20, 14, 21, 19, 23, 20, 1, 22, 20, 24, 13, 13, 22, 12, 19, 1, 12, 10, 12, 23, 21, 1, 7, 13, 13, 3, 1, 24, 10, 22, 22, 0, 9, 20, 1, 14, 12, 19, 22, 1, 1, 12, 3, 22, 7, 5, 22, 9, 15, 22, 9, 11, 20, 20, 14, 9, 12, 23, 20, 21, 14, 13, 22, 19, 7, 13, 5, 10, 0, 5, 1, 21, 22, 5, 22, 8, 7, 9, 7, 13, 5, 11, 23, 19, 9, 23, 22, 11, 5, 23, 20, 1, 15, 22, 11, 22, 15, 12, 19, 3, 22, 12, 7, 13, 11, 22, 3, 8, 24, 5, 22, 13, 22, 3, 21, 9, 9, 7, 11, 0, 22, 23, 9, 8, 22, 10, 12, 22, 5, 11, 23, 20, 13, 1, 23, 22, 14, 10, 1, 11, 12, 9, 22, 7, 19, 12, 22, 21, 1, 12, 22, 22, 1, 24, 23, 15, 12, 5, 13, 11, 9, 3, 12, 1, 23, 23, 1, 7, 3, 11, 9, 22, 23, 13, 22, 22, 9, 26]\n",
      "[25, 24, 3, 9, 23, 1, 7, 22, 19, 22, 15, 0, 10, 23, 8, 7, 10, 12, 22, 22, 14, 23, 22, 22, 11, 7, 5, 24, 19, 1, 10, 7, 13, 14, 12, 22, 10, 5, 10, 23, 12, 12, 16, 8, 15, 21, 21, 1, 1, 16, 22, 22, 10, 15, 15, 1, 14, 12, 12, 14, 19, 1, 1, 7, 12, 23, 23, 23, 11, 12, 7, 23, 3, 22, 7, 23, 3, 12, 13, 22, 23, 3, 21, 21, 9, 15, 22, 15, 21, 11, 23, 15, 22, 1, 5, 23, 5, 13, 23, 22, 15, 13, 10, 16, 5, 21, 19, 10, 20, 16, 11, 13, 11, 1, 7, 1, 7, 10, 23, 1, 23, 11, 11, 26]\n",
      "[25, 24, 13, 1, 13, 23, 23, 21, 23, 13, 10, 21, 21, 22, 1, 9, 9, 1, 13, 1, 10, 13, 11, 23, 22, 22, 21, 9, 24, 20, 12, 11, 15, 1, 0, 14, 3, 14, 3, 22, 22, 10, 19, 21, 12, 1, 21, 12, 13, 23, 22, 5, 19, 11, 23, 22, 12, 14, 13, 8, 21, 19, 13, 9, 22, 5, 15, 12, 22, 10, 22, 15, 22, 22, 3, 13, 23, 7, 14, 8, 0, 8, 13, 19, 8, 5, 14, 10, 14, 10, 23, 22, 21, 1, 22, 22, 11, 10, 0, 9, 1, 23, 5, 1, 21, 22, 1, 10, 13, 9, 13, 19, 22, 8, 5, 10, 12, 10, 19, 1, 5, 21, 20, 10, 21, 20, 13, 22, 12, 14, 21, 13, 1, 11, 10, 8, 14, 11, 10, 0, 23, 14, 20, 23, 22, 7, 19, 9, 1, 24, 13, 20, 14, 10, 19, 13, 22, 22, 5, 21, 10, 0, 10, 21, 14, 19, 20, 9, 9, 10, 0, 13, 15, 14, 22, 3, 8, 1, 23, 8, 12, 15, 5, 20, 14, 22, 11, 10, 7, 0, 22, 5, 3, 11, 13, 8, 19, 3, 8, 10, 22, 14, 23, 1, 14, 23, 12, 12, 12, 21, 14, 22, 7, 11, 21, 22, 14, 22, 1, 0, 12, 12, 20, 5, 15, 23, 24, 19, 7, 22, 7, 22, 11, 15, 11, 9, 9, 5, 19, 5, 13, 23, 11, 13, 7, 24, 21, 0, 10, 23, 9, 14, 11, 11, 1, 26]\n",
      "[25, 24, 15, 15, 1, 13, 20, 20, 10, 1, 23, 13, 22, 13, 13, 22, 23, 13, 10, 13, 13, 1, 13, 1, 14, 22, 19, 19, 23, 15, 13, 21, 10, 9, 22, 5, 0, 10, 1, 7, 11, 10, 22, 14, 10, 20, 13, 13, 11, 19, 13, 7, 10, 23, 3, 9, 10, 20, 19, 23, 13, 23, 0, 15, 13, 23, 13, 13, 13, 23, 22, 10, 19, 11, 24, 15, 23, 15, 3, 23, 11, 22, 14, 10, 12, 14, 21, 20, 14, 13, 22, 13, 1, 10, 12, 23, 19, 23, 22, 23, 21, 7, 1, 14, 16, 14, 20, 1, 21, 19, 14, 12, 22, 13, 22, 19, 20, 23, 13, 23, 7, 3, 3, 19, 10, 9, 10, 20, 24, 23, 7, 15, 1, 22, 10, 23, 1, 1, 13, 15, 12, 22, 19, 10, 13, 14, 5, 0, 23, 9, 14, 10, 14, 14, 14, 12, 24, 7, 22, 13, 19, 20, 20, 15, 13, 7, 7, 24, 14, 3, 14, 11, 23, 7, 5, 13, 19, 19, 13, 12, 10, 9, 9, 15, 20, 13, 13, 10, 13, 0, 19, 1, 3, 14, 14, 19, 13, 1, 10, 22, 13, 1, 1, 21, 13, 14, 22, 11, 7, 13, 13, 19, 5, 23, 5, 22, 11, 12, 5, 5, 1, 15, 12, 11, 22, 10, 11, 23, 23, 21, 8, 10, 19, 7, 7, 16, 10, 19, 5, 23, 21, 16, 1, 20, 3, 13, 22, 23, 13, 13, 12, 12, 3, 10, 5, 14, 15, 13, 7, 22, 12, 12, 23, 13, 13, 1, 14, 9, 7, 11, 12, 5, 21, 21, 22, 22, 10, 22, 12, 10, 19, 24, 10, 15, 15, 5, 10, 22, 19, 7, 19, 20, 13, 15, 21, 13, 5, 22, 13, 1, 10, 7, 3, 10, 12, 23, 20, 12, 13, 7, 5, 10, 13, 1, 14, 1, 5, 10, 22, 13, 21, 10, 22, 7, 13, 9, 16, 14, 9, 10, 10, 22, 24, 3, 13, 11, 11, 20, 21, 26]\n",
      "[25, 24, 11, 20, 11, 22, 13, 1, 9, 10, 1, 9, 9, 1, 9, 15, 14, 3, 10, 5, 14, 1, 11, 5, 1, 22, 13, 14, 11, 15, 19, 14, 19, 0, 14, 22, 14, 9, 15, 22, 5, 12, 14, 22, 15, 11, 3, 10, 23, 20, 12, 12, 12, 19, 12, 22, 9, 8, 21, 5, 22, 1, 22, 10, 15, 22, 7, 7, 22, 23, 15, 12, 16, 5, 21, 12, 5, 1, 12, 22, 15, 7, 22, 11, 9, 1, 23, 5, 12, 7, 23, 10, 10, 15, 5, 20, 14, 20, 10, 1, 3, 21, 22, 10, 23, 8, 14, 15, 10, 13, 19, 5, 19, 13, 22, 0, 23, 13, 11, 21, 8, 23, 19, 21, 1, 19, 22, 20, 1, 1, 20, 3, 12, 15, 22, 15, 9, 9, 12, 12, 23, 15, 19, 22, 21, 1, 23, 12, 12, 13, 20, 23, 11, 23, 5, 15, 22, 0, 20, 19, 10, 5, 12, 5, 19, 5, 22, 20, 13, 21, 22, 13, 22, 9, 14, 5, 11, 12, 19, 22, 19, 22, 21, 19, 19, 1, 22, 22, 15, 7, 22, 19, 5, 21, 0, 5, 21, 1, 22, 7, 10, 0, 21, 23, 14, 19, 12, 5, 22, 8, 22, 23, 11, 7, 5, 19, 1, 20, 21, 22, 14, 22, 21, 13, 5, 15, 22, 16, 13, 15, 21, 8, 7, 5, 3, 1, 7, 5, 22, 10, 20, 22, 10, 10, 23, 1, 16, 13, 24, 22, 23, 13, 21, 14, 0, 9, 22, 3, 11, 7, 13, 5, 13, 1, 14, 22, 23, 8, 15, 20, 20, 22, 23, 20, 1, 15, 16, 12, 16, 11, 7, 11, 23, 22, 22, 15, 9, 11, 12, 12, 0, 7, 22, 7, 22, 11, 23, 16, 19, 11, 21, 23, 7, 11, 1, 19, 21, 3, 8, 22, 24, 11, 5, 5, 14, 11, 13, 3, 11, 9, 9, 7, 1, 14, 3, 7, 23, 1, 23, 1, 14, 21, 13, 23, 24, 23, 12, 12, 20, 15, 9, 10, 22, 13, 5, 14, 19, 12, 5, 22, 22, 22, 15, 13, 12, 16, 1, 15, 22, 20, 19, 13, 11, 7, 20, 20, 9, 15, 3, 15, 3, 23, 20, 3, 7, 22, 22, 13, 24, 20, 13, 16, 10, 12, 5, 5, 7, 15, 7, 15, 15, 21, 0, 3, 14, 22, 15, 15, 15, 15, 15, 26]\n"
     ]
    }
   ],
   "source": [
    "# print('Number of sequences:', len(sequences))\n",
    "print('10 first sequences:')\n",
    "for i in range(10):\n",
    "    print(sequences[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model extraction\n",
    "\n",
    "This is where you will extract your simple own model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Learner, a Comparator, and a Teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymodelextractor.teachers.pac_comparison_strategy import PACComparisonStrategy\n",
    "from pymodelextractor.teachers.general_teacher import GeneralTeacher\n",
    "from pymodelextractor.factories.lstar_factory import LStarFactory\n",
    "\n",
    "name = \"Track: \" + str(TRACK) + \" - DataSet: \" + str(DATASET)\n",
    "\n",
    "target_model = PytorchInference(alphabet, model, name)\n",
    "\n",
    "comparator = PACComparisonStrategy(target_model_alphabet = alphabet, epsilon = 0.01, delta = 0.01)\n",
    "\n",
    "teacher = GeneralTeacher(target_model, comparator)\n",
    "\n",
    "learner = LStarFactory.get_dfa_lstar_learner(max_time=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn and extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Started lstar learning ****\n"
     ]
    }
   ],
   "source": [
    "res = learner.learn(teacher, log_hierachy=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "Once you are satisfied with your model performance, you must write a predict function that takes a sequence as input (list of integers) and returns 0 or 1 (integer type) for the binary classification track and a probability (float type) for the language modeling track.\n",
    "\n",
    "Your model is **NOT** a parameter of this function. You should NOT take care of MLFlow saving here. \n",
    "\n",
    "*For instance, if you want to submit the original model:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and submit \n",
    "This is the creation of the model needed for the submission to the competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'equivalence_queries_count': 1,\n",
       " 'membership_queries_count': 26,\n",
       " 'observation_table': <pymodelextractor.learners.observation_table_learners.general_observation_table.GeneralObservationTable at 0x7f223c9b8910>,\n",
       " 'duration': 3}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythautomata.model_exporters.dot_exporters.dfa_dot_exporting_strategy import DfaDotExportingStrategy\n",
    "res.model._exporting_strategies = [DfaDotExportingStrategy()]\n",
    "res.model.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12539/2988259664.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtest_model_w_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model_w_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/work/NeuralChecker/TAYSIR/utils.py\u001b[0m in \u001b[0;36mtest_model_w_data\u001b[0;34m(target_model, model, sequences)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtarget_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/NeuralChecker/TAYSIR/utils.py\u001b[0m in \u001b[0;36mprocess_query\u001b[0;34m(self, sequence)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0madapted_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapted_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_adapt_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/NeuralChecker/TAYSIR/utils.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(sequence, model)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#Transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/NeuralChecker/TAYSIR/models/1.11.taysir.model/code/tnetwork.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"lm\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_lm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_bin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_bin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/NeuralChecker/TAYSIR/models/1.11.taysir.model/code/tnetwork.py\u001b[0m in \u001b[0;36mpredict_bin\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_bin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/NeuralChecker/TAYSIR/models/1.11.taysir.model/code/tnetwork.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden, full_ret)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"lm\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_lm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_bin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_bin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_ret\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/NeuralChecker/TAYSIR/models/1.11.taysir.model/code/tnetwork.py\u001b[0m in \u001b[0;36mforward_bin\u001b[0;34m(self, x, hidden, full_ret)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_bin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_ret\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         states = [\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pass_recurrent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         ]\n",
      "\u001b[0;32m~/work/NeuralChecker/TAYSIR/models/1.11.taysir.model/code/tnetwork.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         states = [\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pass_recurrent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         ]\n\u001b[1;32m    157\u001b[0m         \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/NeuralChecker/TAYSIR/models/1.11.taysir.model/code/tnetwork.py\u001b[0m in \u001b[0;36m_pass_recurrent\u001b[0;34m(self, word, hidden, b)\u001b[0m\n\u001b[1;32m    335\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhides_pairs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m                     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmachine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/NeuralChecker/TAYSIR/models/1.11.taysir.model/code/lstmx.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hxcx, full_ret)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhxcx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_ret\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhxcx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfull_ret\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/NeuralChecker/TAYSIR/models/1.11.taysir.model/code/lstmx.py\u001b[0m in \u001b[0;36mforward_x\u001b[0;34m(self, x, hxcx)\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0mbatched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mbatched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0mall_h\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/NeuralChecker/TAYSIR/models/1.11.taysir.model/code/lstmx.py\u001b[0m in \u001b[0;36m_run_layer\u001b[0;34m(self, x, hx, cx, t)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m             \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m             \u001b[0mh_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0mc_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1235\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_batched\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1237\u001b[0;31m         ret = _VF.lstm_cell(\n\u001b[0m\u001b[1;32m   1238\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_hh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from utils import test_model_w_data\n",
    "\n",
    "result = test_model_w_data(target_model, res.model, sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.mean(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import test_model\n",
    "\n",
    "result = test_model(target_model, res.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.mean(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment to save predicted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow_exporter.wrapper import MlflowDFA\n",
    "from mlflow_exporter.submit_tools_fix import save_function\n",
    "\n",
    "mlflow_dfa = MlflowDFA(res.model)\n",
    "save_function(mlflow_dfa, len(res.model.alphabet), target_model.name)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "NXdKde0kt3FR",
    "eKzzh3hot9vZ",
    "BMQF46fnw1Zk"
   ],
   "name": "PFA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "122e9f251b80a4a76e7262659287020d96f7188da42b39e3d812967db6c8742d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
