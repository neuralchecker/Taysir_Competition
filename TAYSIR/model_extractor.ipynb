{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAYSIR competition - Track 1 Starter Kit\n",
    "\n",
    "### Welcome!\n",
    "\n",
    "This is a notebook to show the structure of a code to participate to the competition.\n",
    "\n",
    "You can also check the baseline notebook (available in the same archive) for more details about the TAYSIR models and how to use them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare your environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%pip install -q mlflow torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import mlflow\n",
    "from utils import predict, PytorchInference\n",
    "#print('PyTorch version :', torch.__version__)\n",
    "#print('MLflow version :', mlflow.__version__)\n",
    "import sys\n",
    "import pandas as pd\n",
    "#print(\"Your python version:\", sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was tested with:\n",
    "* Torch version: 1.11.0+cu102\n",
    "* MLFlow version: 1.25.1\n",
    "* Python version: 3.8.10 [GCC 9.4.0]\n",
    "\n",
    "Python versions starting at 3.7 are supposed to work (but have not been tested).\n",
    "## Choosing the phase\n",
    "\n",
    "First you must select one of the phases/datasets we provide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACK = 1 #always for his track\n",
    "DATASET = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/03/24 17:44:37 WARNING mlflow.pytorch: Stored model version '1.13.1+cu117' does not match installed PyTorch version '2.0.0+cu117'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TNetwork(\n",
       "  7, 2, patience=5, bidirectional=True\n",
       "  (mach[0]): RNN(6, 32, batch_first=True, bidirectional=True)\n",
       "  (dense): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=2, bias=True)\n",
       "    (1): Sigmoid()\n",
       "    (2): Softmax(dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DistilBertForSequenceClassification\n",
    "\n",
    "model_name = f\"models/1.{DATASET}.taysir.model\"\n",
    "\n",
    "model = mlflow.pytorch.load_model(model_name)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The alphabet contains 6 symbols.\n",
      "The type of the recurrent cells is RNN\n"
     ]
    }
   ],
   "source": [
    "try:#RNN\n",
    "    nb_letters = model.input_size - 1\n",
    "    cell_type = model.cell_type\n",
    "\n",
    "    print(\"The alphabet contains\", nb_letters, \"symbols.\")\n",
    "    print(\"The type of the recurrent cells is\", cell_type.__name__)\n",
    "except:\n",
    "    nb_letters = model.distilbert.config.vocab_size - 2\n",
    "    print(\"The alphabet contains\", nb_letters, \"symbols.\")\n",
    "    print(\"The model is a transformer (DistilBertForSequenceClassification)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "The input data is in the following format :\n",
    "\n",
    "```\n",
    "[Number of sequences] [Alphabet size]\n",
    "[Length of sequence] [List of symbols]\n",
    "[Length of sequence] [List of symbols]\n",
    "[Length of sequence] [List of symbols]\n",
    "...\n",
    "[Length of sequence] [List of symbols]\n",
    "```\n",
    "\n",
    "For example the following data :\n",
    "\n",
    "```\n",
    "5 10\n",
    "6 8 6 5 1 6 7 4 9\n",
    "12 8 6 9 4 6 8 2 1 0 6 5 9\n",
    "7 8 9 4 3 0 4 9\n",
    "4 8 0 4 9\n",
    "8 8 1 5 2 6 0 5 3 9\n",
    "```\n",
    "\n",
    "is composed of 5 sequences and has an alphabet size of 10 (so symbols are between 0 and 9) and the first sequence is composed of 6 symbols (8 6 5 1 6 7 4 9), notice that 8 is the start symbol and 9 is the end symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pythautomata.base_types.alphabet import Alphabet\n",
    "\n",
    "file = f\"datasets/1.{DATASET}.taysir.valid.words\"\n",
    "\n",
    "alphabet = None\n",
    "sequences = []\n",
    "\n",
    "#In the competition the empty sequence is defined as [alphabet_size - 2, alphabet size -1]\n",
    "#For example with the alphabet of size 22 the empty sequence is [20, 21]\n",
    "empty_sequence_len = 2\n",
    "\n",
    "with open(file) as f:\n",
    "    a = f.readline() #Skip first line (number of sequences, alphabet size)\n",
    "    headline = a.split(' ')\n",
    "    alphabet_size = int(headline[1].strip())\n",
    "    alphabet = Alphabet.from_strings([str(x) for x in range(alphabet_size - empty_sequence_len)])\n",
    "    \n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        seq = line.split(' ')\n",
    "        seq = [int(i) for i in seq[1:]] #Remove first value (length of sequence) and cast to int\n",
    "        sequences.append(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable *sequences* is thus **a list of lists**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 first sequences:\n",
      "10000\n",
      "[4, 2, 1, 3, 1, 3, 0, 1, 2, 2, 3, 2, 2, 3, 2, 1, 3, 1, 2, 0, 2, 5]\n",
      "[4, 0, 0, 0, 0, 0, 3, 3, 1, 2, 1, 3, 3, 1, 1, 0, 0, 2, 2, 0, 3, 5]\n",
      "[4, 0, 1, 2, 3, 0, 3, 2, 0, 3, 2, 1, 0, 3, 2, 2, 2, 1, 0, 1, 2, 5]\n",
      "[4, 0, 3, 0, 1, 3, 3, 3, 0, 1, 3, 2, 0, 2, 0, 2, 2, 3, 3, 3, 1, 5]\n",
      "[4, 3, 1, 0, 1, 0, 3, 2, 2, 0, 1, 1, 0, 0, 0, 1, 3, 0, 1, 2, 2, 5]\n",
      "[4, 2, 2, 3, 2, 0, 0, 2, 2, 2, 2, 1, 3, 0, 0, 3, 2, 2, 3, 3, 1, 5]\n",
      "[4, 3, 1, 2, 0, 1, 3, 3, 0, 0, 2, 1, 1, 3, 0, 2, 0, 1, 0, 3, 2, 5]\n",
      "[4, 1, 0, 1, 0, 0, 0, 0, 0, 3, 0, 2, 2, 3, 0, 2, 1, 1, 2, 3, 2, 5]\n",
      "[4, 3, 2, 3, 0, 2, 0, 3, 0, 3, 2, 1, 2, 1, 1, 2, 2, 2, 3, 1, 0, 5]\n",
      "[4, 3, 1, 1, 1, 2, 0, 3, 3, 1, 2, 3, 1, 1, 0, 1, 0, 3, 0, 1, 2, 5]\n"
     ]
    }
   ],
   "source": [
    "# print('Number of sequences:', len(sequences))\n",
    "print('10 first sequences:')\n",
    "print(len(sequences))\n",
    "for i in range(10):\n",
    "    print(sequences[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model extraction\n",
    "\n",
    "This is where you will extract your simple own model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Learner, a Comparator, and a Teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymodelextractor.teachers.pac_comparison_strategy import PACComparisonStrategy\n",
    "from pymodelextractor.teachers.general_teacher import GeneralTeacher\n",
    "from pymodelextractor.factories.lstar_factory import LStarFactory\n",
    "from pythautomata.utilities.uniform_length_sequence_generator import UniformLengthSequenceGenerator\n",
    "\n",
    "name = \"Track: \" + str(TRACK) + \" - DataSet: \" + str(DATASET)\n",
    "\n",
    "target_model = PytorchInference(alphabet, model, name)\n",
    "\n",
    "sequence_generator = UniformLengthSequenceGenerator(alphabet, max_seq_length=1000, min_seq_length=900)\n",
    "\n",
    "comparator = PACComparisonStrategy(target_model_alphabet = alphabet, epsilon = 0.01, delta = 0.01, \n",
    "                                   sequence_generator = sequence_generator)\n",
    "\n",
    "teacher = GeneralTeacher(target_model, comparator)\n",
    "\n",
    "learner = LStarFactory.get_dfa_lstar_learner(max_time=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn and extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Started lstar learning ****\n"
     ]
    }
   ],
   "source": [
    "res = learner.learn(teacher, log_hierachy=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test extracted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import test_model_w_data, test_model\n",
    "import numpy as np\n",
    "\n",
    "result = test_model_w_data(target_model, res.model, sequences)\n",
    "np.mean(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.612"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = test_model(target_model, res.model, max_seq_len=1000, min_seq_len=50, sequence_amount=1000)\n",
    "np.mean(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = test_model(target_model, res.model, max_seq_len=1000, min_seq_len=900, sequence_amount=1000)\n",
    "np.mean(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final response info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model:\n",
      "- State amount -> 2\n",
      "- Membership queries -> 9\n",
      "- Equivalence queries -> 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Final model:\")\n",
    "print(\"- State amount -> \" + str(len(res.model.states)))\n",
    "print(\"- Membership queries -> \" + str(res.info[\"membership_queries_count\"]))\n",
    "print(\"- Equivalence queries -> \" + str(res.info[\"equivalence_queries_count\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence len: 2\n",
      "Table rows: 9\n",
      "Table columns: 1\n"
     ]
    }
   ],
   "source": [
    "max_exp = 0\n",
    "for k in res.info['observation_table'].exp:\n",
    "    if len(k) > max_exp:\n",
    "        max_exp = len(k)\n",
    "        \n",
    "max_blue = 0\n",
    "for k in res.info['observation_table'].blue:\n",
    "    if len(k) > max_blue:\n",
    "        max_blue = len(k)\n",
    "        \n",
    "print(\"Max sequence len: \" + str(max_blue + max_exp))\n",
    "print(\"Table rows: \" + str(len(res.info['observation_table'].blue)+len(res.info['observation_table'].red)))\n",
    "print(\"Table columns: \" + str(len(res.info['observation_table'].exp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "Once you are satisfied with your model performance, you must write a predict function that takes a sequence as input (list of integers) and returns 0 or 1 (integer type) for the binary classification track and a probability (float type) for the language modeling track.\n",
    "\n",
    "Your model is **NOT** a parameter of this function. You should NOT take care of MLFlow saving here. \n",
    "\n",
    "*For instance, if you want to submit the original model:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and submit \n",
    "This is the creation of the model needed for the submission to the competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment to save predicted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission created at predicted_models/Track: 1 - DataSet: 1.zip.\n"
     ]
    }
   ],
   "source": [
    "from wrapper import MlflowDFA\n",
    "from submit_tools_fix import save_function\n",
    "\n",
    "mlflow_dfa = MlflowDFA(res.model)\n",
    "save_function(mlflow_dfa, len(res.model.alphabet), target_model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythautomata.model_exporters.dot_exporters.dfa_dot_exporting_strategy import DfaDotExportingStrategy\n",
    "res.model._exporting_strategies = [DfaDotExportingStrategy()]\n",
    "#res.model.export()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "NXdKde0kt3FR",
    "eKzzh3hot9vZ",
    "BMQF46fnw1Zk"
   ],
   "name": "PFA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "122e9f251b80a4a76e7262659287020d96f7188da42b39e3d812967db6c8742d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
