{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAYSIR competition - Track 1 Starter Kit\n",
    "\n",
    "### Welcome!\n",
    "\n",
    "This is a notebook to show the structure of a code to participate to the competition.\n",
    "\n",
    "You can also check the baseline notebook (available in the same archive) for more details about the TAYSIR models and how to use them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare your environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -q mlflow torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import mlflow\n",
    "from utils import predict, PytorchInference\n",
    "#print('PyTorch version :', torch.__version__)\n",
    "#print('MLflow version :', mlflow.__version__)\n",
    "import sys\n",
    "import pandas as pd\n",
    "#print(\"Your python version:\", sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was tested with:\n",
    "* Torch version: 1.11.0+cu102\n",
    "* MLFlow version: 1.25.1\n",
    "* Python version: 3.8.10 [GCC 9.4.0]\n",
    "\n",
    "Python versions starting at 3.7 are supposed to work (but have not been tested).\n",
    "## Choosing the phase\n",
    "\n",
    "First you must select one of the phases/datasets we provide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACK = 1 #always for his track\n",
    "DATASET = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/03/20 18:08:39 WARNING mlflow.pytorch: Stored model version '1.11.0+cu102' does not match installed PyTorch version '1.10.0+cu102'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(68, 12, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 12)\n",
       "      (LayerNorm): LayerNorm((12,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=12, out_features=12, bias=True)\n",
       "            (k_lin): Linear(in_features=12, out_features=12, bias=True)\n",
       "            (v_lin): Linear(in_features=12, out_features=12, bias=True)\n",
       "            (out_lin): Linear(in_features=12, out_features=12, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((12,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=12, out_features=12, bias=True)\n",
       "            (lin2): Linear(in_features=12, out_features=12, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((12,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=12, out_features=12, bias=True)\n",
       "  (classifier): Linear(in_features=12, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DistilBertForSequenceClassification\n",
    "\n",
    "model_name = f\"models/1.{DATASET}.taysir.model\"\n",
    "\n",
    "model = mlflow.pytorch.load_model(model_name)\n",
    "\n",
    "sequence = [4, 2, 1, 3, 1, 3, 0, 1, 2, 2, 3, 2, 2, 3, 2, 1, 3, 1, 2, 0, 2, 5]\n",
    "\n",
    "#pred = predict(sequence, model)\n",
    "#pred\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The alphabet contains 66 symbols.\n",
      "The model is a transformer (DistilBertForSequenceClassification)\n"
     ]
    }
   ],
   "source": [
    "try:#RNN\n",
    "    nb_letters = model.input_size - 1\n",
    "    cell_type = model.cell_type\n",
    "\n",
    "    print(\"The alphabet contains\", nb_letters, \"symbols.\")\n",
    "    print(\"The type of the recurrent cells is\", cell_type.__name__)\n",
    "except:\n",
    "    nb_letters = model.distilbert.config.vocab_size - 2\n",
    "    print(\"The alphabet contains\", nb_letters, \"symbols.\")\n",
    "    print(\"The model is a transformer (DistilBertForSequenceClassification)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "The input data is in the following format :\n",
    "\n",
    "```\n",
    "[Number of sequences] [Alphabet size]\n",
    "[Length of sequence] [List of symbols]\n",
    "[Length of sequence] [List of symbols]\n",
    "[Length of sequence] [List of symbols]\n",
    "...\n",
    "[Length of sequence] [List of symbols]\n",
    "```\n",
    "\n",
    "For example the following data :\n",
    "\n",
    "```\n",
    "5 10\n",
    "6 8 6 5 1 6 7 4 9\n",
    "12 8 6 9 4 6 8 2 1 0 6 5 9\n",
    "7 8 9 4 3 0 4 9\n",
    "4 8 0 4 9\n",
    "8 8 1 5 2 6 0 5 3 9\n",
    "```\n",
    "\n",
    "is composed of 5 sequences and has an alphabet size of 10 (so symbols are between 0 and 9) and the first sequence is composed of 6 symbols (8 6 5 1 6 7 4 9), notice that 8 is the start symbol and 9 is the end symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({8, 12, 38, 36, 58, 33, 0, 3, 37, 51, 23, 45, 32, 19, 4, 30, 16, 42, 25, 17, 26, 22, 49, 9, 13, 39, 1, 44, 61, 27, 57, 53, 60, 50, 31, 18, 7, 2, 24, 20, 28, 29, 55, 48, 47, 11, 54, 56, 59, 5, 6, 43, 52, 35, 15, 14, 40, 64, 62, 10, 46, 21, 41, 63, 34})\n"
     ]
    }
   ],
   "source": [
    "from pythautomata.base_types.alphabet import Alphabet\n",
    "\n",
    "file = f\"datasets/1.{DATASET}.taysir.valid.words\"\n",
    "\n",
    "alphabet = None\n",
    "sequences = []\n",
    "\n",
    "with open(file) as f:\n",
    "    a = f.readline() #Skip first line (number of sequences, alphabet size)\n",
    "    headline = a.split(' ')\n",
    "    alphabet_size = int(headline[1].strip())\n",
    "    alphabet = Alphabet.from_strings([str(x) for x in range(alphabet_size - 1)])\n",
    "    print(alphabet)\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        seq = line.split(' ')\n",
    "        seq = [int(i) for i in seq[1:]] #Remove first value (length of sequence) and cast to int\n",
    "        sequences.append(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable *sequences* is thus **a list of lists**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 10000\n",
      "10 first sequences:\n",
      "[64, 34, 11, 17, 9, 50, 40, 45, 55, 8, 58, 24, 34, 3, 62, 36, 60, 55, 53, 9, 55, 65]\n",
      "[64, 39, 15, 4, 38, 5, 38, 63, 0, 51, 58, 14, 5, 32, 49, 61, 23, 24, 63, 57, 39, 65]\n",
      "[64, 40, 0, 39, 17, 61, 59, 50, 40, 5, 24, 48, 0, 31, 21, 38, 19, 19, 59, 9, 28, 65]\n",
      "[64, 48, 34, 44, 34, 52, 21, 37, 18, 21, 37, 14, 17, 9, 31, 11, 61, 24, 3, 9, 56, 65]\n",
      "[64, 8, 19, 13, 61, 25, 13, 2, 42, 17, 9, 29, 44, 28, 41, 1, 32, 18, 54, 34, 18, 65]\n",
      "[64, 15, 28, 18, 40, 3, 31, 21, 34, 4, 16, 50, 20, 14, 51, 46, 29, 36, 6, 0, 2, 65]\n",
      "[64, 38, 33, 60, 8, 6, 34, 57, 37, 60, 55, 35, 52, 50, 63, 45, 53, 40, 7, 45, 20, 65]\n",
      "[64, 41, 38, 37, 58, 32, 27, 17, 0, 21, 14, 50, 59, 25, 5, 7, 54, 53, 36, 11, 6, 65]\n",
      "[64, 60, 59, 4, 48, 17, 27, 55, 32, 45, 29, 60, 53, 12, 34, 62, 48, 28, 3, 23, 24, 65]\n",
      "[64, 17, 36, 60, 61, 24, 28, 60, 3, 39, 44, 41, 32, 4, 1, 41, 3, 3, 51, 50, 45, 65]\n"
     ]
    }
   ],
   "source": [
    "print('Number of sequences:', len(sequences))\n",
    "print('10 first sequences:')\n",
    "for i in range(10):\n",
    "    print(sequences[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model extraction\n",
    "\n",
    "This is where you will extract your simple own model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Learner, a Comparator, and a Teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymodelextractor.teachers.pac_comparison_strategy import PACComparisonStrategy\n",
    "from pymodelextractor.teachers.general_teacher import GeneralTeacher\n",
    "from pymodelextractor.factories.lstar_factory import LStarFactory\n",
    "\n",
    "name = \"Track: \" + str(TRACK) + \" - DataSet: \" + str(DATASET)\n",
    "\n",
    "target_model = PytorchInference(alphabet, model, name)\n",
    "\n",
    "comparator = PACComparisonStrategy(target_model_alphabet = alphabet, epsilon = 0.01, delta = 0.01)\n",
    "\n",
    "teacher = GeneralTeacher(target_model, comparator)\n",
    "\n",
    "learner = LStarFactory.get_dfa_lstar_learner()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn and extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Started lstar learning ****\n",
      "**** Learning finished in 5.132320165634155s using 2 counterexamples & final model ended with 9 states ****\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = learner.learn(teacher, log_hierachy=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "Once you are satisfied with your model performance, you must write a predict function that takes a sequence as input (list of integers) and returns 0 or 1 (integer type) for the binary classification track and a probability (float type) for the language modeling track.\n",
    "\n",
    "Your model is **NOT** a parameter of this function. You should NOT take care of MLFlow saving here. \n",
    "\n",
    "*For instance, if you want to submit the original model:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and submit \n",
    "This is the creation of the model needed for the submission to the competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymodelextractor.learners.learning_result.LearningResult at 0x7fea6c69df10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'equivalence_queries_count': 3,\n",
       " 'membership_queries_count': 3584,\n",
       " 'observation_table': <pymodelextractor.learners.observation_table_learners.general_observation_table.GeneralObservationTable at 0x7feac0909bb0>,\n",
       " 'duration': 5.132308483123779}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythautomata.model_exporters.dot_exporters.dfa_dot_exporting_strategy import DfaDotExportingStrategy\n",
    "res.model._exporting_strategies = [DfaDotExportingStrategy()]\n",
    "res.model.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import test_model\n",
    "\n",
    "result = test_model(target_model, res.model, sequence_length =100, sequence_amount=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment to save predicted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from mlflow_exporter.wrapper import MlflowDFA\\nfrom mlflow_exporter.submit_tools_fix import save_function\\n\\nmlflow_dfa = MlflowDFA(res.model)\\nsave_function(mlflow_dfa, len(res.model.alphabet), target_model.name)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from mlflow_exporter.wrapper import MlflowDFA\n",
    "from mlflow_exporter.submit_tools_fix import save_function\n",
    "\n",
    "mlflow_dfa = MlflowDFA(res.model)\n",
    "save_function(mlflow_dfa, len(res.model.alphabet), target_model.name)'''"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "NXdKde0kt3FR",
    "eKzzh3hot9vZ",
    "BMQF46fnw1Zk"
   ],
   "name": "PFA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "122e9f251b80a4a76e7262659287020d96f7188da42b39e3d812967db6c8742d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
