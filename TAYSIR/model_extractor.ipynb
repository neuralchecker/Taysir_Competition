{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAYSIR competition - Track 1 Starter Kit\n",
    "\n",
    "### Welcome!\n",
    "\n",
    "This is a notebook to show the structure of a code to participate to the competition.\n",
    "\n",
    "You can also check the baseline notebook (available in the same archive) for more details about the TAYSIR models and how to use them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare your environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlflow in /opt/conda/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.9/site-packages (2.0.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.9/site-packages (4.27.4)\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade mlflow torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import mlflow\n",
    "from utils import predict, PytorchInference\n",
    "#print('PyTorch version :', torch.__version__)\n",
    "#print('MLflow version :', mlflow.__version__)\n",
    "import sys\n",
    "import pandas as pd\n",
    "#print(\"Your python version:\", sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was tested with:\n",
    "* Torch version: 1.11.0+cu102\n",
    "* MLFlow version: 1.25.1\n",
    "* Python version: 3.8.10 [GCC 9.4.0]\n",
    "\n",
    "Python versions starting at 3.7 are supposed to work (but have not been tested).\n",
    "## Choosing the phase\n",
    "\n",
    "First you must select one of the phases/datasets we provide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACK = 1 #always for his track\n",
    "DATASET = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/04/12 22:08:09 WARNING mlflow.pytorch: Stored model version '1.13.1+cu117' does not match installed PyTorch version '2.0.0+cu117'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TNetwork(\n",
       "  7, 2, patience=5, bidirectional=True\n",
       "  (mach[0]): RNN(6, 32, batch_first=True, bidirectional=True)\n",
       "  (dense): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=2, bias=True)\n",
       "    (1): Sigmoid()\n",
       "    (2): Softmax(dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DistilBertForSequenceClassification\n",
    "\n",
    "model_name = f\"models/1.{DATASET}.taysir.model\"\n",
    "\n",
    "model = mlflow.pytorch.load_model(model_name)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The alphabet contains 6 symbols.\n",
      "The type of the recurrent cells is RNN\n"
     ]
    }
   ],
   "source": [
    "try:#RNN\n",
    "    nb_letters = model.input_size - 1\n",
    "    cell_type = model.cell_type\n",
    "\n",
    "    print(\"The alphabet contains\", nb_letters, \"symbols.\")\n",
    "    print(\"The type of the recurrent cells is\", cell_type.__name__)\n",
    "except:\n",
    "    nb_letters = model.distilbert.config.vocab_size - 2\n",
    "    print(\"The alphabet contains\", nb_letters, \"symbols.\")\n",
    "    print(\"The model is a transformer (DistilBertForSequenceClassification)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "The input data is in the following format :\n",
    "\n",
    "```\n",
    "[Number of sequences] [Alphabet size]\n",
    "[Length of sequence] [List of symbols]\n",
    "[Length of sequence] [List of symbols]\n",
    "[Length of sequence] [List of symbols]\n",
    "...\n",
    "[Length of sequence] [List of symbols]\n",
    "```\n",
    "\n",
    "For example the following data :\n",
    "\n",
    "```\n",
    "5 10\n",
    "6 8 6 5 1 6 7 4 9\n",
    "12 8 6 9 4 6 8 2 1 0 6 5 9\n",
    "7 8 9 4 3 0 4 9\n",
    "4 8 0 4 9\n",
    "8 8 1 5 2 6 0 5 3 9\n",
    "```\n",
    "\n",
    "is composed of 5 sequences and has an alphabet size of 10 (so symbols are between 0 and 9) and the first sequence is composed of 6 symbols (8 6 5 1 6 7 4 9), notice that 8 is the start symbol and 9 is the end symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pythautomata.base_types.alphabet import Alphabet\n",
    "\n",
    "file = f\"datasets/1.{DATASET}.taysir.valid.words\"\n",
    "\n",
    "alphabet = None\n",
    "sequences = []\n",
    "\n",
    "#In the competition the empty sequence is defined as [alphabet_size - 2, alphabet size -1]\n",
    "#For example with the alphabet of size 22 the empty sequence is [20, 21]\n",
    "empty_sequence_len = 2\n",
    "\n",
    "with open(file) as f:\n",
    "    a = f.readline() #Skip first line (number of sequences, alphabet size)\n",
    "    headline = a.split(' ')\n",
    "    alphabet_size = int(headline[1].strip())\n",
    "    alphabet = Alphabet.from_strings([str(x) for x in range(alphabet_size - empty_sequence_len)])\n",
    "    \n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        seq = line.split(' ')\n",
    "        seq = [int(i) for i in seq[1:]] #Remove first value (length of sequence) and cast to int\n",
    "        sequences.append(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable *sequences* is thus **a list of lists**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 first sequences:\n",
      "10000\n",
      "[4, 2, 1, 3, 1, 3, 0, 1, 2, 2, 3, 2, 2, 3, 2, 1, 3, 1, 2, 0, 2, 5]\n",
      "[4, 0, 0, 0, 0, 0, 3, 3, 1, 2, 1, 3, 3, 1, 1, 0, 0, 2, 2, 0, 3, 5]\n",
      "[4, 0, 1, 2, 3, 0, 3, 2, 0, 3, 2, 1, 0, 3, 2, 2, 2, 1, 0, 1, 2, 5]\n",
      "[4, 0, 3, 0, 1, 3, 3, 3, 0, 1, 3, 2, 0, 2, 0, 2, 2, 3, 3, 3, 1, 5]\n",
      "[4, 3, 1, 0, 1, 0, 3, 2, 2, 0, 1, 1, 0, 0, 0, 1, 3, 0, 1, 2, 2, 5]\n",
      "[4, 2, 2, 3, 2, 0, 0, 2, 2, 2, 2, 1, 3, 0, 0, 3, 2, 2, 3, 3, 1, 5]\n",
      "[4, 3, 1, 2, 0, 1, 3, 3, 0, 0, 2, 1, 1, 3, 0, 2, 0, 1, 0, 3, 2, 5]\n",
      "[4, 1, 0, 1, 0, 0, 0, 0, 0, 3, 0, 2, 2, 3, 0, 2, 1, 1, 2, 3, 2, 5]\n",
      "[4, 3, 2, 3, 0, 2, 0, 3, 0, 3, 2, 1, 2, 1, 1, 2, 2, 2, 3, 1, 0, 5]\n",
      "[4, 3, 1, 1, 1, 2, 0, 3, 3, 1, 2, 3, 1, 1, 0, 1, 0, 3, 0, 1, 2, 5]\n"
     ]
    }
   ],
   "source": [
    "# print('Number of sequences:', len(sequences))\n",
    "print('10 first sequences:')\n",
    "print(len(sequences))\n",
    "for i in range(10):\n",
    "    print(sequences[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model extraction\n",
    "\n",
    "This is where you will extract your simple own model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Learner, a Comparator, and a Teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymodelextractor.teachers.pac_comparison_strategy import PACComparisonStrategy\n",
    "from pymodelextractor.teachers.general_teacher import GeneralTeacher\n",
    "from pymodelextractor.factories.lstar_factory import LStarFactory\n",
    "from pythautomata.utilities.uniform_length_sequence_generator import UniformLengthSequenceGenerator\n",
    "from pymodelextractor.learners.observation_tree_learners.kearns_vazirani_learner import KearnsVaziraniLearner\n",
    "\n",
    "name = \"Track: \" + str(TRACK) + \" - DataSet: \" + str(DATASET)\n",
    "\n",
    "target_model = PytorchInference(alphabet, model, name)\n",
    "\n",
    "sequence_generator = UniformLengthSequenceGenerator(alphabet, max_seq_length=1000, min_seq_length=900)\n",
    "\n",
    "comparator = PACComparisonStrategy(target_model_alphabet = alphabet, epsilon = 0.01, delta = 0.01, \n",
    "                                   sequence_generator = sequence_generator)\n",
    "\n",
    "teacher = GeneralTeacher(target_model, comparator)\n",
    "\n",
    "# Choose algorithm (LStar, KV)\n",
    "algorithm = 'LStar'\n",
    "\n",
    "# LStar learner\n",
    "if(algorithm == 'LStar'): learner = LStarFactory.get_dfa_lstar_learner(max_time=5)\n",
    "\n",
    "#Kearns Vazirani learner\n",
    "if(algorithm == 'KV'):  learner = KearnsVaziraniLearner()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn and extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Started lstar learning ****\n"
     ]
    }
   ],
   "source": [
    "if(algorithm == 'LStar'): \n",
    "    res = learner.learn(teacher, log_hierachy=1)\n",
    "elif(algorithm == 'KV'): \n",
    "    res = learner.learn(teacher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Observation Table in pickle (only for LStar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "if(algorithm == 'LStar'):\n",
    "    obs_table = res.info['observation_table']\n",
    "\n",
    "    with open('predicted_models/observation_table.pickle', 'wb') as handle:\n",
    "        pickle.dump(obs_table, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Load data example\n",
    "\n",
    "with open('predicted_models/observation_table.pickle', 'rb') as handle:\n",
    "    unserialized_data = pickle.load(handle)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test extracted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_21306/4107195545.py\", line 4, in <module>\n",
      "    result = test_model_w_data(target_model, res.model, sequences)\n",
      "  File \"/home/jovyan/work/TAYSIR/utils.py\", line 88, in test_model_w_data\n",
      "    results.append(model.process_query(sequence) == target_model.process_query(sequence))\n",
      "  File \"/home/jovyan/work/TAYSIR/utils.py\", line 59, in process_query\n",
      "    return predict(adapted_sequence, self._model) == 1\n",
      "  File \"/home/jovyan/work/TAYSIR/utils.py\", line 11, in predict\n",
      "    value = model.predict(model.one_hot_encode(sequence))\n",
      "  File \"/home/jovyan/work/TAYSIR/models/1.1.taysir.model/code/tnetwork.py\", line 221, in predict\n",
      "    return self.predict_bin(x)\n",
      "  File \"/home/jovyan/work/TAYSIR/models/1.1.taysir.model/code/tnetwork.py\", line 224, in predict_bin\n",
      "    out, _ = self(x)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/jovyan/work/TAYSIR/models/1.1.taysir.model/code/tnetwork.py\", line 150, in forward\n",
      "    return self.forward_bin(x, hidden, full_ret)\n",
      "  File \"/home/jovyan/work/TAYSIR/models/1.1.taysir.model/code/tnetwork.py\", line 153, in forward_bin\n",
      "    words = unpad(unbatch(x))\n",
      "  File \"/home/jovyan/work/TAYSIR/models/1.1.taysir.model/code/tnetwork.py\", line 434, in unpad\n",
      "    for t, sym in enumerate(word):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/torch/_tensor.py\", line 940, in __iter__\n",
      "    return iter(self.unbind(0))\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/opt/conda/lib/python3.9/inspect.py\", line 1541, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/opt/conda/lib/python3.9/inspect.py\", line 1499, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/opt/conda/lib/python3.9/inspect.py\", line 709, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/opt/conda/lib/python3.9/inspect.py\", line 755, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/opt/conda/lib/python3.9/posixpath.py\", line 392, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_21306/4107195545.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model_w_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/TAYSIR/utils.py\u001b[0m in \u001b[0;36mtest_model_w_data\u001b[0;34m(target_model, model, sequences)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtarget_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/TAYSIR/utils.py\u001b[0m in \u001b[0;36mprocess_query\u001b[0;34m(self, sequence)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0madapted_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapted_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/TAYSIR/utils.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(sequence, model)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/TAYSIR/models/1.1.taysir.model/code/tnetwork.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    220\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_lm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_bin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/TAYSIR/models/1.1.taysir.model/code/tnetwork.py\u001b[0m in \u001b[0;36mpredict_bin\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_bin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/TAYSIR/models/1.1.taysir.model/code/tnetwork.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden, full_ret)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_lm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_bin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/TAYSIR/models/1.1.taysir.model/code/tnetwork.py\u001b[0m in \u001b[0;36mforward_bin\u001b[0;34m(self, x, hidden, full_ret)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_bin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_ret\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         states = [\n",
      "\u001b[0;32m~/work/TAYSIR/models/1.1.taysir.model/code/tnetwork.py\u001b[0m in \u001b[0;36munpad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0munbroken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msym\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m             )\n\u001b[0;32m--> 940\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2076\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2077\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2078\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2077\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2078\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2079\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2080\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "from utils import test_model_w_data, test_model\n",
    "import numpy as np\n",
    "\n",
    "result = test_model_w_data(target_model, res.model, sequences)\n",
    "np.mean(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = test_model(target_model, res.model, max_seq_len=1000, min_seq_len=50, sequence_amount=1000)\n",
    "np.mean(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = test_model(target_model, res.model, max_seq_len=1000, min_seq_len=900, sequence_amount=1000)\n",
    "np.mean(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final response info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final model:\")\n",
    "print(\"- State amount -> \" + str(len(res.model.states)))\n",
    "print(\"- Membership queries -> \" + str(res.info[\"membership_queries_count\"]))\n",
    "print(\"- Equivalence queries -> \" + str(res.info[\"equivalence_queries_count\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_exp = 0\n",
    "for k in res.info['observation_table'].exp:\n",
    "    if len(k) > max_exp:\n",
    "        max_exp = len(k)\n",
    "        \n",
    "max_blue = 0\n",
    "for k in res.info['observation_table'].blue:\n",
    "    if len(k) > max_blue:\n",
    "        max_blue = len(k)\n",
    "        \n",
    "print(\"Max sequence len: \" + str(max_blue + max_exp))\n",
    "print(\"Table rows: \" + str(len(res.info['observation_table'].blue)+len(res.info['observation_table'].red)))\n",
    "print(\"Table columns: \" + str(len(res.info['observation_table'].exp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "Once you are satisfied with your model performance, you must write a predict function that takes a sequence as input (list of integers) and returns 0 or 1 (integer type) for the binary classification track and a probability (float type) for the language modeling track.\n",
    "\n",
    "Your model is **NOT** a parameter of this function. You should NOT take care of MLFlow saving here. \n",
    "\n",
    "*For instance, if you want to submit the original model:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and submit \n",
    "This is the creation of the model needed for the submission to the competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment to save predicted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from wrapper import MlflowDFA\n",
    "from submit_tools_fix import save_function\n",
    "\n",
    "mlflow_dfa = MlflowDFA(res.model)\n",
    "save_function(mlflow_dfa, len(res.model.alphabet), target_model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythautomata.model_exporters.dot_exporters.dfa_dot_exporting_strategy import DfaDotExportingStrategy\n",
    "res.model._exporting_strategies = [DfaDotExportingStrategy()]\n",
    "#res.model.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "table_0, table_1 = None, None\n",
    "with open('predicted_models/observation_table_0.pickle', 'rb') as handle:\n",
    "    table_0 = pickle.load(handle)\n",
    "    \n",
    "with open('predicted_models/observation_table_1.pickle', 'rb') as handle:\n",
    "    table_1 = pickle.load(handle)\n",
    "    \n",
    "with open('predicted_models/observation_table_2.pickle', 'rb') as handle:\n",
    "    table_2 = pickle.load(handle)\n",
    "    \n",
    "print(table_0)\n",
    "print(table_1)\n",
    "print(table_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/04/12 22:29:01 WARNING mlflow.pytorch: Stored model version '1.13.1+cu117' does not match installed PyTorch version '2.0.0+cu117'\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import pickle\n",
    "from utils import predict, PytorchInference\n",
    "import numpy as np\n",
    "from wrapper import MlflowDFA\n",
    "from submit_tools_fix import save_function\n",
    "from pythautomata.utilities.uniform_word_sequence_generator import UniformWordSequenceGenerator\n",
    "from pythautomata.model_exporters.dot_exporters.dfa_dot_exporting_strategy import DfaDotExportingStrategy\n",
    "from pymodelextractor.teachers.pac_comparison_strategy import PACComparisonStrategy\n",
    "from pymodelextractor.teachers.general_teacher import GeneralTeacher\n",
    "from pymodelextractor.factories.lstar_factory import LStarFactory\n",
    "from pythautomata.base_types.alphabet import Alphabet\n",
    "from utils import test_model\n",
    "from pymodelextractor.learners.observation_table_learners.translators.partial_dfa_translator import PartialDFATranslator\n",
    "\n",
    "TRACK = 1 #always for his track\n",
    "DATASET = 2\n",
    "\n",
    "max_extraction_time = 60\n",
    "max_sequence_len = 80\n",
    "min_sequence_len = 10\n",
    "\n",
    "counter = 0\n",
    "observation_table = None\n",
    "\n",
    "model_name = f\"models/1.{DATASET}.taysir.model\"\n",
    "model = mlflow.pytorch.load_model(model_name)\n",
    "model.eval()\n",
    "\n",
    "file = f\"datasets/1.{DATASET}.taysir.valid.words\"\n",
    "\n",
    "empty_sequence_len = 2\n",
    "with open(file) as f:\n",
    "    a = f.readline() #Skip first line (number of sequences, alphabet size)\n",
    "    headline = a.split(' ')\n",
    "    alphabet_size = int(headline[1].strip())\n",
    "    alphabet = Alphabet.from_strings([str(x) for x in range(alphabet_size - empty_sequence_len)])\n",
    "\n",
    "name = \"Track: \" + str(TRACK) + \" - DataSet: \" + str(DATASET) + \"-  partial n° \" + str(counter)\n",
    "target_model = PytorchInference(alphabet, model, name)\n",
    "\n",
    "sequence_generator = UniformWordSequenceGenerator(alphabet, max_seq_length=max_sequence_len,\n",
    "                                                        min_seq_length=min_sequence_len)\n",
    "\n",
    "comparator = PACComparisonStrategy(target_model_alphabet = alphabet, epsilon = 0.01, delta = 0.01,\n",
    "                                   sequence_generator = sequence_generator)\n",
    "\n",
    "teacher = GeneralTeacher(target_model, comparator)\n",
    "\n",
    "learner = LStarFactory.get_partial_dfa_lstar_learner(max_time=max_extraction_time)\n",
    "\n",
    "name = \"Track: \" + str(TRACK) + \" - DataSet: \" + str(DATASET) + \"-  partial n° \" + str(counter)\n",
    "res = learner.learn(teacher, observation_table)\n",
    "\n",
    "#print(observation_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'equivalence_queries_count': 1, 'membership_queries_count': 17, 'observation_table': <pymodelextractor.learners.observation_table_learners.general_observation_table.GeneralObservationTable object at 0x7fb2e08c4f70>, 'duration': 60}\n"
     ]
    }
   ],
   "source": [
    "print(res.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(res.model.states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.model.name = \"Dataset\"+str(DATASET)+\"-1Acc\"\n",
    "res.model.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fast_dfa_converter import FastDeterministicFiniteAutomatonConverter as Converter\n",
    "\n",
    "fast_dfa = Converter().to_fast_dfa(res.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission created at predicted_models/Track: 1 - DataSet: 2-  partial n° 0.zip.\n"
     ]
    }
   ],
   "source": [
    "from wrapper import MlflowDFA\n",
    "from submit_tools_fix import save_function\n",
    "\n",
    "#mlflow_dfa = MlflowDFA(fast_dfa)\n",
    "save_function(fast_dfa, len(res.model.alphabet), target_model.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "NXdKde0kt3FR",
    "eKzzh3hot9vZ",
    "BMQF46fnw1Zk"
   ],
   "name": "PFA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "122e9f251b80a4a76e7262659287020d96f7188da42b39e3d812967db6c8742d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
