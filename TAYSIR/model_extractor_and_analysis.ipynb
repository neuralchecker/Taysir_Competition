{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAYSIR competition - Track 1 Starter Kit\n",
    "\n",
    "### Welcome!\n",
    "\n",
    "This is a notebook to show the structure of a code to participate to the competition.\n",
    "\n",
    "You can also check the baseline notebook (available in the same archive) for more details about the TAYSIR models and how to use them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare your environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade mlflow torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import mlflow\n",
    "from utils import predict, PytorchInference\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persisting results for logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persist_results(dataset, learning_result, max_extraction_time):\n",
    "    result = dict()\n",
    "    extracted_model = learning_result.model\n",
    "    \n",
    "    result.update({ \n",
    "                'Instance': dataset,\n",
    "                'Number of Extracted States': len(extracted_model.states) ,   \n",
    "                'EquivalenceQuery': learning_result.info['equivalence_queries_count'], \n",
    "                'MembershipQuery': learning_result.info['membership_queries_count'], \n",
    "                'Duration': learning_result.info['duration'], \n",
    "                'TimeBound': max_extraction_time\n",
    "                })\n",
    "    \n",
    "    wandb.config.update(result)\n",
    "    wandb.finish()\n",
    "    \n",
    "    # Soon: history!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from utils import predict, PytorchInference\n",
    "import numpy as np\n",
    "from wrapper import MlflowDFA\n",
    "from submit_tools_fix import save_function\n",
    "from pythautomata.utilities.uniform_word_sequence_generator import UniformWordSequenceGenerator\n",
    "from pythautomata.model_exporters.dot_exporters.dfa_dot_exporting_strategy import DfaDotExportingStrategy\n",
    "from pymodelextractor.teachers.pac_comparison_strategy import PACComparisonStrategy\n",
    "from pymodelextractor.teachers.general_teacher import GeneralTeacher\n",
    "from pymodelextractor.factories.lstar_factory import LStarFactory\n",
    "from pythautomata.base_types.alphabet import Alphabet\n",
    "from utils import test_model\n",
    "from pymodelextractor.learners.observation_table_learners.translators.partial_dfa_translator import PartialDFATranslator\n",
    "import wandb\n",
    "\n",
    "TRACK = 1 #always for his track\n",
    "DATASET = 7\n",
    "\n",
    "max_extraction_time = 60\n",
    "max_sequence_len = 80\n",
    "min_sequence_len = 10\n",
    "epsilon = 0.01\n",
    "delta = 0.01\n",
    "\n",
    "# params of wandb log\n",
    "params = dict()\n",
    "params['DATASET_7'] = {\"max_extraction_time\":max_extraction_time, \"max_sequence_len\":max_sequence_len, \n",
    "                       \"min_sequence_len\":min_sequence_len, \"epsilon\":epsilon, \"delta\":delta}\n",
    "# Initialize wandb\n",
    "wandb.init(\n",
    "        # Set the project where this run will be logged\n",
    "        project=\"taysir_track_1\",\n",
    "        # Track hyperparameters and run metadata\n",
    "        config=params\n",
    "    ) \n",
    "\n",
    "counter = 0\n",
    "observation_table = None\n",
    "\n",
    "model_name = f\"models/1.{DATASET}.taysir.model\"\n",
    "model = mlflow.pytorch.load_model(model_name)\n",
    "model.eval()\n",
    "\n",
    "file = f\"datasets/1.{DATASET}.taysir.valid.words\"\n",
    "\n",
    "empty_sequence_len = 2\n",
    "with open(file) as f:\n",
    "    a = f.readline() #Skip first line (number of sequences, alphabet size)\n",
    "    headline = a.split(' ')\n",
    "    alphabet_size = int(headline[1].strip())\n",
    "    alphabet = Alphabet.from_strings([str(x) for x in range(alphabet_size - empty_sequence_len)])\n",
    "\n",
    "name = \"Track: \" + str(TRACK) + \" - DataSet: \" + str(DATASET) + \"-  partial n° \" + str(counter)\n",
    "target_model = PytorchInference(alphabet, model, name)\n",
    "\n",
    "sequence_generator = UniformWordSequenceGenerator(alphabet, max_seq_length=max_sequence_len,\n",
    "                                                        min_seq_length=min_sequence_len)\n",
    "\n",
    "comparator = PACComparisonStrategy(target_model_alphabet = alphabet, epsilon = epsilon, delta = delta,\n",
    "                                   sequence_generator = sequence_generator)\n",
    "\n",
    "teacher = GeneralTeacher(target_model, comparator)\n",
    "\n",
    "learner = LStarFactory.get_partial_dfa_lstar_learner(max_time=max_extraction_time)\n",
    "\n",
    "name = \"Track: \" + str(TRACK) + \" - DataSet: \" + str(DATASET) + \"-  partial n° \" + str(counter)\n",
    "res = learner.learn(teacher, observation_table)\n",
    "\n",
    "persist_results(DATASET, res, max_extraction_time)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some quick metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Result info:\", res.info)\n",
    "print(\"---------------------------\")\n",
    "print(\"Number of extracted states:\", len(res.model.states))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with uniform length sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get validation sequence max length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = test_model(target_model, res.model, max_seq_len=1000, min_seq_len=50, sequence_amount=1000)\n",
    "np.mean(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.model.name = \"Dataset\"+str(DATASET)+\"-1Acc\"\n",
    "res.model.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fast_dfa_converter import FastDeterministicFiniteAutomatonConverter as Converter\n",
    "\n",
    "fast_dfa = Converter().to_fast_dfa(res.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrapper import MlflowDFA\n",
    "from submit_tools_fix import save_function\n",
    "\n",
    "#mlflow_dfa = MlflowDFA(fast_dfa)\n",
    "save_function(fast_dfa, len(res.model.alphabet), target_model.name)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "NXdKde0kt3FR",
    "eKzzh3hot9vZ",
    "BMQF46fnw1Zk"
   ],
   "name": "PFA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "122e9f251b80a4a76e7262659287020d96f7188da42b39e3d812967db6c8742d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
